{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faa40c44",
   "metadata": {},
   "source": [
    "# Likelihood Optimization of gas Kinematics in IFUs (LOKI)\n",
    "## Fitting example: MIRI + PSF model\n",
    "\n",
    "Michael Reefe\n",
    "\n",
    "This example notebook provides a tutorial on how to run LOKI on a multi-channel MIRI/MRS cube, including a PSF model to separate out light from a bright quasar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "288ac322",
   "metadata": {},
   "source": [
    "In this example, we'll utilize the multi-processing capabilities of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323538a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "procs = addprocs(Sys.CPU_THREADS, exeflags=\"--heap-size-hint=4G\")\n",
    "\n",
    "@everywhere begin\n",
    "    using Pkg\n",
    "    Pkg.activate(dirname(@__DIR__))\n",
    "    Pkg.instantiate()\n",
    "    Pkg.precompile()\n",
    "    using Loki\n",
    "    using Unitful \n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2862b182",
   "metadata": {},
   "source": [
    "Now we want to load in our data. For this example, we'll be using the channel 1-4 data for NGC 7469, which is located in the same folder as this notebook. The JWST reduced data does not include a redshift, so we must provide the redshift ourselves.  We can use the `from_fits` function to load in the JWST-formatted FITS files, along with the redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c04fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The redshift of the target object: NGC 7469\n",
    "z = 0.016317\n",
    "# The semicolon at the end suppresses printing the output Observation object, which is long and not very enlightening\n",
    "obs = from_fits([\"Level3_ch1-long_s3d.fits.gz\", \n",
    "                 \"Level3_ch1-medium_s3d.fits.gz\", \n",
    "                 \"Level3_ch1-short_s3d.fits.gz\",\n",
    "                 \"Level3_ch2-long_s3d.fits.gz\",\n",
    "                 \"Level3_ch2-medium_s3d.fits.gz\",\n",
    "                 \"Level3_ch2-short_s3d.fits.gz\",\n",
    "                 \"Level3_ch3-long_s3d.fits.gz\",\n",
    "                 \"Level3_ch3-medium_s3d.fits.gz\",\n",
    "                 \"Level3_ch3-short_s3d.fits.gz\",\n",
    "                 \"Level3_ch4-long_s3d.fits.gz\",\n",
    "                 \"Level3_ch4-medium_s3d.fits.gz\",\n",
    "                 \"Level3_ch4-short_s3d.fits.gz\"], z);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aea827e4",
   "metadata": {},
   "source": [
    "Next, we create some variables that we will use later. We will be fitting multi-channel data, and we can take the `name` property from the Observation object we just loaded in to get the name of the target. Here, `run_name` is just a unique identifier that we will use for this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f602574",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0   # since we are including data from all 4 channels, this is just a placeholder\n",
    "nm = replace(obs.name, \" \" => \"_\") \n",
    "run_name = \"$(nm)_ch$(channel)_psf_model\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f793d58",
   "metadata": {},
   "source": [
    "Before fitting, we want to do some pre-processing on the data. We want to convert the data to the rest-frame, mast out / interpolate any bad pixels, and replace the JWST pipeline-generated errors with some more realistic ones.  We also need to create our PSF model that we will use to model the bright nuclear point-source from the AGN.  All of this is achieved in the next block of code. This is also where we will combine data from multiple channels into a single cube using the `combine_channels!` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfbae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isfile(\"$nm.channel$channel.rest_frame.fits\")\n",
    "    # If we've already performed this step in a previous run, just load in the pre-processed data\n",
    "    obs = from_fits([\"$nm.channel$channel.rest_frame.fits\"], obs.z);\n",
    "    \n",
    "else\n",
    "    # First, generate the PSF models\n",
    "    generate_psf_model!(obs)\n",
    "\n",
    "    # Convert to rest-frame wavelength vector, and mask out bad spaxels\n",
    "    correct!(obs)\n",
    "\n",
    "    # Fit cubic spline to the PSF\n",
    "    for band in (:A, :B, :C)\n",
    "        for channel in (1, 2, 3, 4)\n",
    "            chband = Symbol(band, channel)\n",
    "            splinefit_psf_model!(obs.channels[chband], 100)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Reproject the sub-channels onto the same WCS grid and combine them into one full channel\n",
    "    # - The [:A1, :B1, :C1, ...] vector gives the names of each channel to concatenate. By default, JWST subchannels are\n",
    "    #   given labels of \"A\" for short, \"B\" for medium, and \"C\" for long, followed by the channel number. Make sure you \n",
    "    #   list them in order of increasing wavelength, otherwise the resampling won't work correctly. \n",
    "    # - The \"out_id\" argument will determine the label given to the combined channel data. \n",
    "    combine_channels!(obs, [:A1,:B1,:C1,:A2,:B2,:C2,:A3,:B3,:C3,:A4,:B4,:C4], out_id=channel, order=1, \n",
    "        adjust_wcs_headerinfo=true, extract_from_ap=0., max_λ=17.2u\"μm\")\n",
    "\n",
    "    # rotate to the RA/Dec axes on the sky\n",
    "    rotate_to_sky_axes!(obs.channels[channel])\n",
    "\n",
    "    # We interpolate any rogue NaNs using a linear interpolation, since the MPFIT minimizer does not handle NaNs well.\n",
    "    interpolate_nans!(obs.channels[channel])\n",
    "\n",
    "    # Finally, we calculate the statistical errors (i.e. the standard deviation of the residuals with a cubic spline fit)\n",
    "    # and replace the errors in the cube with these, since the provided errors are typically underestimated.\n",
    "    # You can skip this step if you wish to use the default errors.\n",
    "    calculate_statistical_errors!(obs.channels[channel])\n",
    "    \n",
    "    # Save the pre-processed data as a FITS file so it can be quickly reloaded later\n",
    "    save_fits(\".\", obs, [channel]);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e827079a",
   "metadata": {},
   "source": [
    "We now need to create the full 3D nuclear template out of the PSF model.  Conceptually, all this does is multiply the normalized PSF with the spectrum of the brightest spaxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuc_temp = generate_nuclear_template(obs.channels[channel], 0.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baaa4ddb",
   "metadata": {},
   "source": [
    "Finally, we create the `CubeFitter` object and call the `fit_cube!` function to fit the data. We've set a few more additional options in the CubeFitter here.  In particular, pay attention to the \"templates\" and \"template_names\" arguments, which specify the 3D nuclear template model that we created above, and give it a unique identifier.  For more information about what the other arguments do, refer to the \"Usage\" section in the README file.\n",
    "\n",
    "Note: we're doing the whole shebang for this example, so it may take a few hours to complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see a full list of keyword arguments, please refer to the docstring, which can be accessed by typing `?CubeFitter` in the command\n",
    "# line after importing Loki.\n",
    "cube_fitter = CubeFitter(\n",
    "    obs.channels[channel], \n",
    "    obs.z, \n",
    "    run_name; \n",
    "    parallel=true, \n",
    "    parallel_strategy=\"pmap\",\n",
    "    plot_spaxels=:pyplot, \n",
    "    plot_maps=true, \n",
    "    save_fits=true,\n",
    "    silicate_absorption=\"d+\",\n",
    "    extinction_screen=true, \n",
    "    use_pah_templates=true, \n",
    "    fit_sil_emission=false, \n",
    "    fit_stellar_continuum=false, \n",
    "    save_full_model=true, \n",
    "    map_snr_thresh=3., \n",
    "    templates=nuc_temp, \n",
    "    template_names=[\"nuclear\"], \n",
    "    subtract_cubic_spline=true,\n",
    ")\n",
    "\n",
    "# Call the fit_cube! function on the cube_fitter object\n",
    "fit_cube!(cube_fitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the worker processes\n",
    "rmprocs(procs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05295663",
   "metadata": {},
   "source": [
    "And the results can be found in the \"output_[run_name]\" directory, just like the other examples!  Here is a showcase of a few of the fits to some individual spaxels across various locations:\n",
    "\n",
    "![](./NGC7469.spaxel_10_31.png)\n",
    "![](./NGC7469.spaxel_25_26.png)\n",
    "![](./NGC7469.spaxel_27_26.png)\n",
    "![](./NGC7469.spaxel_32_12.png)\n",
    "\n",
    "The orange line shows the final model.  The decomposed components of the model consist of:\n",
    "- Thermal dust continuum, in gray\n",
    "- The AGN PSF model, in dark green\n",
    "- PAHs, in blue\n",
    "- Emission lines, in purple\n",
    "- Extinction, in dotted gray (read from the right axis)\n",
    "\n",
    "If you're interested in what the 2D parameter maps should looks like from this fit, check out the README file.  The examples shown there are from this model.\n",
    "\n",
    "Notice that in some of the fits, the model does not do too well at reproducing the continuum on the far left side (the shortest wavelengths).  This is because we neglected to include any continuum component that could be important here, such as either a hot dust component or a stellar continuum.  One way to alleviate this would be by changing the `fit_stellar_continuum` option in the `CubeFitter` to true.  If you do so, make sure you have installed the python FSPS library!  Or you could instead set `fit_sil_emission` to true to fit a hot silicate dust emission component.  This will also likely change the recovered amplitudes on the AGN PSF template since they can become degenerate at these short wavelengths, so just be aware of that.  A good sanity check for this is to look at the fit results for the brightest spaxel (which should be close to the center of the cube, somewhere around x,y=25,25) - the PSF model is based on this spectrum, so the model should be pretty much 100% composed of the dark green AGN PSF template in this spaxel.  If it's not, you might need to look into either constraining the PSF template amplitude parameters or removing the degenerate model components.\n",
    "\n",
    "Now that you've run this model, be sure to check out the continuation in \"example_MIRI_qso_model\", which will take the results of this model and use them to reconstruct a 1D quasar spectrum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.9",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
